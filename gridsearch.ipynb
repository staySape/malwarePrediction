{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs and Function Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:07.812409Z",
     "start_time": "2020-07-05T08:19:03.243777Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:35:00.743803Z",
     "start_time": "2020-07-05T07:35:00.739455Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pdb import set_trace\n",
    "import logging \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging is important\n",
    "logger = logging.getLogger()\n",
    "dstamp = datetime.now().strftime('%M_%d')\n",
    "fhandler = logging.FileHandler(filename= dstamp + 'session.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:07.816165Z",
     "start_time": "2020-07-05T08:19:07.813868Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:07.936041Z",
     "start_time": "2020-07-05T08:19:07.817941Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:20.329778Z",
     "start_time": "2020-07-05T08:19:07.938188Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:22.309086Z",
     "start_time": "2020-07-05T08:19:20.330947Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, tree, linear_model, neighbors\\\n",
    ", naive_bayes, ensemble, discriminant_analysis, gaussian_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:22.314753Z",
     "start_time": "2020-07-05T08:19:22.311772Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-05T11:45:33.341Z"
    }
   },
   "source": [
    "from dask_ml.model_selection import HyperbandSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:22.389136Z",
     "start_time": "2020-07-05T08:19:22.316943Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class gridSearchShotgun:\n",
    "#reference from https://github.com/davidsbatista/ still not sure if he's a wrestler\n",
    "    def __init__(self, ltEstParamPair, X_train, X_test,  y_train, y_test):\n",
    "        self.pair = ltEstParamPair\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.grid_searches = {}\n",
    "        self.dfres = pd.DataFrame()\n",
    "        self.dfpredScore = pd.DataFrame()\n",
    "        self.dffeatImp = pd.DataFrame()\n",
    "        self.pxfig = {}\n",
    "        \n",
    "        \n",
    "    def fit(self, cv=5, n_jobs=-1, verbose=1, scoring=None, refit=True):\n",
    "        for eppair in self.pair:\n",
    "            model = eppair[0]\n",
    "            model_name = model.__class__.__name__\n",
    "            print(f'Running gridSearchCV for {model_name}')\n",
    "            params = eppair[1]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(self.X_train,self.y_train)\n",
    "            self.grid_searches[model_name] = gs \n",
    "\n",
    "\n",
    "    def score_summary(self):\n",
    "        frames = []\n",
    "        for name, grid_search in self.grid_searches.items():\n",
    "            frame = pd.DataFrame(grid_search.cv_results_)\n",
    "            #frame = frame.filter(regex='^(?!.*param_).*$') by default creates grid of params\n",
    "            # params_grid is the result\n",
    "            frame['estimator'] = name\n",
    "            frames.append(frame)\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        #df = df.sort_values([sort_by], ascending=False)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop([ 'index'], 1) \n",
    "        ltleftItems = ['estimator', 'mean_test_score']\n",
    "        columns = df.columns.to_list()\n",
    "        columns = [col for col in columns if col not in ltleftItems]\n",
    "        columns = ltleftItems+columns\n",
    "        df = df[columns]\n",
    "        self.dfres = df \n",
    "    \n",
    "    def predict(self):\n",
    "        ltkey = []\n",
    "        ltpredScore = []\n",
    "        ltParams = []\n",
    "        for key, est in self.grid_searches.items():\n",
    "            ltkey.append(key)\n",
    "            ltParams.append(est.best_params_)\n",
    "            preds = est.best_estimator_.predict(self.X_test)\n",
    "            acc = metrics.accuracy_score(self.y_test, preds)\n",
    "            ltpredScore.append(acc)\n",
    "        dtPredScore  = {'estimator': ltkey\n",
    "                       , 'params': ltParams\n",
    "                       , 'score': ltpredScore } \n",
    "        \n",
    "        dfScore = pd.DataFrame.from_dict(dtPredScore)\n",
    "        self.dfpredScore = dfScore\n",
    "    \n",
    "    def featImp(self, colnames):\n",
    "        dffeat = pd.DataFrame()\n",
    "        \n",
    "        dffeat['colName'] = colnames\n",
    "        for est,grid_search in gsjob.grid_searches.items():\n",
    "            dffeat[est]  = grid_search.best_estimator_.feature_importances_\n",
    "        self.dffeatImp  = dffeat\n",
    "    \n",
    "    def plot(self,x = 'param_n_estimators', y = 'mean_test_score' ):\n",
    "        df = self.dfres\n",
    "        df = df.sort_values(x)\n",
    "        fig = px.scatter(df, x = x, y = y, color = 'estimator' )\n",
    "        fig.show()\n",
    "        self.pxfig[x] = fig\n",
    "    \n",
    "    def chain(self):\n",
    "        self.fit()\n",
    "        self.score_summary()\n",
    "        self.predict()\n",
    "        #self.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleOut(obj, fname):\n",
    "    fout =  open(fname, 'wb')\n",
    "    pickle.dump(obj, fout)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Importing pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:19:35.322173Z",
     "start_time": "2020-07-05T08:19:22.390120Z"
    }
   },
   "outputs": [],
   "source": [
    "dfMain = pd.read_pickle('formodelling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfMain.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:53:38.916661Z",
     "start_time": "2020-07-05T07:53:36.850926Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'HasDetections')\n",
    "y = df['HasDetections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:53:49.556966Z",
     "start_time": "2020-07-05T07:53:38.917809Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pair Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:53:49.560953Z",
     "start_time": "2020-07-05T07:53:49.558221Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "epPair= [ [ensemble.AdaBoostClassifier(), \n",
    "            {'learning_rate': [.1,.2,.3,.4,.5,1,5]\n",
    "             , 'n_estimators': [8, 16, 32, 64, 128]\n",
    "            }] \n",
    "          , [ensemble.RandomForestClassifier() , \n",
    "            {'n_estimators': [8, 16, 32, 64, 128]\n",
    "            , 'max_features': ['auto', 'sqrt']\n",
    "            , 'max_depth': [10, 32, 55, 77, 100]\n",
    "            , 'min_samples_split': [2, 5, 10]\n",
    "            , 'min_samples_leaf': [1, 2, 4]\n",
    "            , 'bootstrap': [True, False]\n",
    "            }]\n",
    "    \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:53:49.686399Z",
     "start_time": "2020-07-05T07:53:49.683456Z"
    }
   },
   "outputs": [],
   "source": [
    "gsjob = gridSearchShotgun(epPair, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:53:56.442980Z",
     "start_time": "2020-07-05T07:53:56.251494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gridSearchCV for AdaBoostClassifier\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  4.1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gsjob.chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsjob.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsjob.dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsjob.dfpredScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames= X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsjob.featImp(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsjob.dffeatImp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleOut(rsjob, 'many.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47.15px",
    "left": "1154px",
    "top": "252.433px",
    "width": "160.533px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
